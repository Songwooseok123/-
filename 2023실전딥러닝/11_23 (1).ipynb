{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"gpuType":"T4","mount_file_id":"1z5neqIhU5kgWUgss4tjbTHjB1jVR6OPW","authorship_tag":"ABX9TyOrrV54//exsdiCDQnTU8Lv"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU"},"cells":[{"cell_type":"code","execution_count":null,"metadata":{"id":"0hQnwQRMZP3K"},"outputs":[],"source":["import os\n","import matplotlib.pyplot as plt\n","import tensorflow as tf\n","from tensorflow import keras\n","import numpy as np\n","import time\n"]},{"cell_type":"code","source":["!pip install konlpy"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"iJA1wGYJaLnG","executionInfo":{"status":"ok","timestamp":1700721157348,"user_tz":-540,"elapsed":11258,"user":{"displayName":"송우석","userId":"17544301414917834266"}},"outputId":"b4dd4b1b-4e16-4e59-9819-19a5a9c644f2"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Requirement already satisfied: konlpy in /usr/local/lib/python3.10/dist-packages (0.6.0)\n","Requirement already satisfied: JPype1>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from konlpy) (1.4.1)\n","Requirement already satisfied: lxml>=4.1.0 in /usr/local/lib/python3.10/dist-packages (from konlpy) (4.9.3)\n","Requirement already satisfied: numpy>=1.6 in /usr/local/lib/python3.10/dist-packages (from konlpy) (1.23.5)\n","Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from JPype1>=0.7.0->konlpy) (23.2)\n"]}]},{"cell_type":"code","source":["with open('/content/drive/MyDrive/Colab Notebooks/실전딥러닝2023/kor.txt') as f :\n","  lines = f.readlines()"],"metadata":{"id":"sA-SDE3QaN-g"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["targ, inp, trash = zip(*[line.split('\\t') for line in lines])"],"metadata":{"id":"bjiltpUtaVxa"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["inp[-1]"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":72},"id":"TbM7fXeja4Lu","executionInfo":{"status":"ok","timestamp":1700721157829,"user_tz":-540,"elapsed":22,"user":{"displayName":"송우석","userId":"17544301414917834266"}},"outputId":"0471b3a8-8d76-4f94-af2f-e40cedcffdac"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["'의심의 여지 없이 세상에는 어떤 남자이든 정확히 딱 알맞는 여자와 결혼하거나 그 반대의 상황이 존재하지. 그런데 인간이 수백 명의 사람만 알고 지내는 사이가 될 기회를 갖는다고 생각해 보면, 또 그 수백 명 중 열여 명 쯤 이하만 잘 알 수 있고, 그리고 나서 그 열여 명 중에 한두 명만 친구가 될 수 있다면, 그리고 또 만일 우리가 이 세상에 살고 있는 수백만 명의 사람들만 기억하고 있다면, 딱 맞는 남자는 지구가 생겨난 이래로 딱 맞는 여자를 단 한번도 만난 적이 없을 수도 있을 거라는 사실을 쉽게 눈치챌 수 있을 거야.'"],"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"}},"metadata":{},"execution_count":5}]},{"cell_type":"code","source":["from konlpy.tag import Hannanum\n","\n","hannanum = Hannanum()\n","\n","hannanum.morphs(inp[-1])"],"metadata":{"id":"qWkHOdsHavlW"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["import nltk\n","from nltk.tokenize import word_tokenize\n","nltk.download('punkt')\n","word_tokenize(targ[-1].lower())"],"metadata":{"id":"t9QwdcHNbM6h"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["x_tokens = [hannanum.morphs(x) for x in inp]\n","y_tokens = [word_tokenize(x.lower()) for x in targ]"],"metadata":{"id":"CvrlYRWmcVQ1"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["def text_encoding(lines):\n","\n","    vocab, index = {}, 3  # start indexing from 1\n","\n","    vocab['<pad>'] = 0  # add a padding token\n","\n","    vocab['<bos>'] = 1  # begin of sentence\n","\n","    vocab['<eos>'] = 2  # end of sentence\n","\n","    preprocessed_tokens = []\n","\n","    maxlen = -1\n","\n","    for sentence in lines:\n","\n","        for token in sentence:\n","\n","            if token not in vocab:\n","\n","                vocab[token] = index\n","\n","                index += 1\n","\n","        if maxlen < len(sentence):\n","\n","            maxlen = len(sentence)\n","\n","    arr = np.zeros((len(lines), maxlen+2), dtype='int32')\n","\n","    for i, sentence in enumerate(lines):\n","\n","        for j, token in enumerate(sentence):\n","\n","            arr[i, j+1] = vocab[token]\n","\n","        arr[i, 0] = vocab['<bos>']\n","\n","        arr[i, len(sentence)+1] = vocab['<eos>']\n","\n","    return arr, vocab\n"],"metadata":{"id":"__XpwRpqdBlf"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["#그리디 서치에 버그가 있다."],"metadata":{"id":"LKv3iVsjdMjI"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["x_train,x_vocab = text_encoding(x_tokens)\n","y_train,y_vocab = text_encoding(y_tokens)"],"metadata":{"id":"VfSJqNOgeqiE"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["inverse_x_vocab = {index : token for token,index in x_vocab.items()}\n","inverse_y_vocab = {index : token for token,index in y_vocab.items()}"],"metadata":{"id":"CqIM8zHBeqtD"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["def text_decoding(line, vo):\n","  return [vo[x] for x in line]"],"metadata":{"id":"gdPfFcntfby3"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["print(text_decoding(x_train[-1],inverse_x_vocab))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"liMBcMX2fmB4","executionInfo":{"status":"ok","timestamp":1700721194639,"user_tz":-540,"elapsed":23,"user":{"displayName":"송우석","userId":"17544301414917834266"}},"outputId":"f7ee0144-cbba-46d7-d2c9-c32aeaf9191f"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["['<bos>', '의심', '의', '여', '이', '지', '없이', '세상', '에는', '어떤', '남자', '이', '든', '정확히', '딱', '알맞', '는', '여자', '와', '결혼', '하', '거나', '그', '반대', '의', '상황', '이', '존재', '하', '지', '.', '그런데', '인간', '이', '수백', '명', '의', '사람', '만', '알', '고', '지내', '는', '사이', '가', '되', 'ㄹ', '기회', '를', '갖', '는다', '고', '생각', '하', '어', '보', '면', ',', '또', '그', '수백', '명', '중', '열', '여', '명', '쯤', '이하', '만', '잘', '알', 'ㄹ', '수', '있', '고', ',', '그리고', '나', '서', '그', '열', '여', '명', '중', '에', '한두', '명', '만', '친구', '가', '되', 'ㄹ', '수', '있', '다면', ',', '그리고', '또', '만', '이', 'ㄹ', '우리', '가', '이', '세상', '에', '살', '고', '있', '는', '수백만', '명', '의', '사람들', '만', '기억', '하고', '있', '다면', ',', '딱', '맞', '는', '남자', '는', '지구', '가', '생기', '어', '나', 'ㄴ', '이래', '로', '딱', '맞', '는', '여자', '를', '달', 'ㄴ', '한번', '도', '만나', 'ㄴ', '적', '이', '없', '을', '수', '도', '있', '을', '것', '이', '라는', '사실', '을', '쉽', '게', '눈치채', 'ㄹ', '수', '있', '을', '것', '이', '야', '.', '<eos>']\n"]}]},{"cell_type":"code","source":["x_train.shape"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"GgPVMUwOfsYl","executionInfo":{"status":"ok","timestamp":1700721194639,"user_tz":-540,"elapsed":21,"user":{"displayName":"송우석","userId":"17544301414917834266"}},"outputId":"ec94de29-6f25-4c3c-d8a0-1e3298c05ea0"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["(5870, 169)"]},"metadata":{},"execution_count":15}]},{"cell_type":"code","source":["np.savez('/content/drive/MyDrive/Colab Notebooks/실전딥러닝2023/kor-eng',x_train = x_train, y_train= y_train)"],"metadata":{"id":"nbjsrCCHf3g4"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["import json\n","with open('/content/drive/MyDrive/Colab Notebooks/실전딥러닝2023/krvocab.json','w') as f :\n","  json.dump(x_vocab,f)\n","with open('/content/drive/MyDrive/Colab Notebooks/실전딥러닝2023/envocab.json','w') as f :\n","  json.dump(y_vocab,f)"],"metadata":{"id":"JbmOq39gg1Qr"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["npzfile = np.load('/content/drive/MyDrive/Colab Notebooks/실전딥러닝2023/kor-eng.npz')\n","x_train = npzfile['x_train']\n","y_train = npzfile['y_train']"],"metadata":{"id":"8kQzi6FphP5X"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["with open('/content/drive/MyDrive/Colab Notebooks/실전딥러닝2023/krvocab.json','rb') as f :\n","  x_vocab = json.load(f)\n","with open('/content/drive/MyDrive/Colab Notebooks/실전딥러닝2023/envocab.json','rb') as f :\n","  y_vocab = json.load(f)"],"metadata":{"id":"YkZiFrYchhqT"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["inverse_x_vocab = {index : token for token,index in x_vocab.items()}\n","inverse_y_vocab = {index : token for token,index in y_vocab.items()}"],"metadata":{"id":"OM95IBNGh5Fj"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["buffer_size = len(x_train)\n","batch_size = 16\n","embedding_dim = 1024\n","latent_dim = 1024\n","x_vocab_size = len(x_vocab)\n","y_vocab_size = len(y_vocab)\n","dataset = tf.data.Dataset.from_tensor_slices((x_train,y_train)).shuffle(buffer_size)\n","dataset =dataset.batch(batch_size)"],"metadata":{"id":"XygfJKt-iAOe"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["for example_input_batch,example_target_batch in dataset.take(1):\n","  break"],"metadata":{"id":"8x2D89jOjr6J"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["example_input_batch = example_input_batch[:,:np.max(np.count_nonzero(example_input_batch,axis =1))]\n","example_target_batch = example_target_batch[:,:np.max(np.count_nonzero(example_target_batch,axis =1))]"],"metadata":{"id":"nL9ps2YUi6VH"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["example_input_batch.shape"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"oLfeJYzNjaJ-","executionInfo":{"status":"ok","timestamp":1700721201563,"user_tz":-540,"elapsed":36,"user":{"displayName":"송우석","userId":"17544301414917834266"}},"outputId":"74873e19-c55e-46c8-ea61-9c0985a719a4"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["TensorShape([16, 23])"]},"metadata":{},"execution_count":24}]},{"cell_type":"code","source":["def build_encoder():\n","  input_seq = tf.keras.layers.Input((None,))\n","  x= tf.keras.layers.Embedding(x_vocab_size, embedding_dim)(input_seq)\n","  x,s1 = tf.keras.layers.GRU(latent_dim,name = 'encoder_gru1',\n","                             return_sequences = True,\n","                             return_state = True,\n","                             recurrent_initializer='glorot_uniform')(x,mask=tf.cast(input_seq !=0,bool))\n","  x,s2 = tf.keras.layers.GRU(latent_dim,name = 'encoder_gru2',\n","                             return_sequences = True,\n","                             return_state = True,\n","                             recurrent_initializer='glorot_uniform')(x,mask=tf.cast(input_seq !=0,bool))\n","  x,s3 = tf.keras.layers.GRU(latent_dim,name = 'encoder_gru3',\n","                             return_sequences = True,\n","                             return_state = True,\n","                             recurrent_initializer='glorot_uniform')(x,mask=tf.cast(input_seq !=0,bool))\n","  model = tf.keras.Model(input_seq,[x,s1,s2,s3])\n","  return model"],"metadata":{"id":"ZLt8zgKej1TO"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["encoder = build_encoder()"],"metadata":{"id":"ZPagWZ2Ylbpj"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["example_input_batch.shape"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"8mylFop7ldyP","executionInfo":{"status":"ok","timestamp":1700721217298,"user_tz":-540,"elapsed":5,"user":{"displayName":"송우석","userId":"17544301414917834266"}},"outputId":"96a050bc-0069-483c-87d7-f18041cafe34"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["TensorShape([16, 23])"]},"metadata":{},"execution_count":28}]},{"cell_type":"code","source":["last_output, last_state1, last_state2, last_state3 = encoder(example_input_batch)"],"metadata":{"id":"b9N69IlZlqzo"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["last_output.shape"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"OTrUOW5cly9T","executionInfo":{"status":"ok","timestamp":1700721220904,"user_tz":-540,"elapsed":17,"user":{"displayName":"송우석","userId":"17544301414917834266"}},"outputId":"2dd58a1f-0664-4666-d762-3772ec166854"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["TensorShape([16, 23, 1024])"]},"metadata":{},"execution_count":30}]},{"cell_type":"code","source":["def build_decoder():\n","  target_seq = tf.keras.layers.Input((None,))\n","  s1 = tf.keras.layers.Input((latent_dim,))\n","  s2 = tf.keras.layers.Input((latent_dim,))\n","  s3 = tf.keras.layers.Input((latent_dim,))\n","\n","  embedding = tf.keras.layers.Embedding(y_vocab_size, embedding_dim)(target_seq)\n","  x,output_s1 = tf.keras.layers.GRU(latent_dim,name = 'decoder_gru1',\n","                             return_sequences = True,\n","                             return_state = True,\n","                             recurrent_initializer='glorot_uniform')(embedding,initial_state =s1,mask=tf.cast(target_seq !=0,bool))\n","\n","  x,output_s2 = tf.keras.layers.GRU(latent_dim,name = 'decoder_gru2',\n","                             return_sequences = True,\n","                             return_state = True,\n","                             recurrent_initializer='glorot_uniform')(x,initial_state =s2,mask=tf.cast(target_seq !=0,bool))\n","  x,output_s3 = tf.keras.layers.GRU(latent_dim,name = 'decoder_gru3',\n","                             return_sequences = True,\n","                             return_state = True,\n","                             recurrent_initializer='glorot_uniform')(x,initial_state =s3,mask=tf.cast(target_seq !=0,bool))\n","  logits = tf.keras.layers.Dense(y_vocab_size)(x)\n","  model = tf.keras.Model([target_seq,s1,s2,s3],[logits,output_s1,output_s2,output_s3])\n","  return model"],"metadata":{"id":"5onrPNMEl0q_"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["decoder = build_decoder()"],"metadata":{"id":"iR1rOHkvnJ54"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["logits ,s1,s2,s3 =decoder([example_target_batch,last_state1,last_state2,last_state3])"],"metadata":{"id":"vXdIWv1PnMJU"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["logits.shape"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"VteNQexhnUjv","executionInfo":{"status":"ok","timestamp":1700721225755,"user_tz":-540,"elapsed":39,"user":{"displayName":"송우석","userId":"17544301414917834266"}},"outputId":"ddf325ca-5a39-4a42-d4c7-0d91138ca2c6"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["TensorShape([16, 20, 3141])"]},"metadata":{},"execution_count":34}]},{"cell_type":"code","source":["s1.shape"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"0Eh7Ta9rnVWi","executionInfo":{"status":"ok","timestamp":1700721225755,"user_tz":-540,"elapsed":37,"user":{"displayName":"송우석","userId":"17544301414917834266"}},"outputId":"8180cfb3-29b2-4f71-a7fc-e6be9cd4bafd"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["TensorShape([16, 1024])"]},"metadata":{},"execution_count":35}]},{"cell_type":"code","source":["loss_func = tf.keras.losses.SparseCategoricalCrossentropy(from_logits =True, reduction ='none')\n","def batch_loss(y_true, y_pred):\n","  loss = loss_func(y_true,y_pred)\n","  mask = tf.cast(y_true != 0, tf.float32)\n","  loss = loss *mask\n","  return tf.reduce_sum(loss)/tf.reduce_sum(mask)\n"],"metadata":{"id":"GM1vBxD_nWy5"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["batch_loss(example_target_batch[:,1:],logits[:,:-1,:])"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"k6jx0u-9n7J_","executionInfo":{"status":"ok","timestamp":1700721225755,"user_tz":-540,"elapsed":30,"user":{"displayName":"송우석","userId":"17544301414917834266"}},"outputId":"8fca5cb7-6cc0-4ff7-c05d-09c79ae02218"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["<tf.Tensor: shape=(), dtype=float32, numpy=8.052269>"]},"metadata":{},"execution_count":37}]},{"cell_type":"code","source":["optimizer = tf.keras.optimizers.Adam(1e-4)\n","def predict(x,y,training=True):\n","  _,ls1,ls2,ls3 = encoder(x,training =training)\n","  logits, _,_,_ = decoder([y,ls1,ls2,ls3],training = training)\n","  return logits"],"metadata":{"id":"UJJRn3-RoBhp"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["def train_step(x,y,t_v):\n","  x= x[:,:tf.reduce_max(tf.math.count_nonzero(x,axis=1))]\n","  y= y[:,:tf.reduce_max(tf.math.count_nonzero(y,axis=1))]\n","  with tf.GradientTape() as tape:\n","    logits  =predict(x,y)\n","    loss = batch_loss(y[:,1:],logits[:,:-1,:])\n","  gradients = tape.gradient(loss,t_v)\n","  optimizer.apply_gradients(zip(gradients, t_v))\n","  return loss"],"metadata":{"id":"GdNQiqrHofet"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["t_v = encoder.trainable_variables +decoder.trainable_variables\n","\n","for epoch in range(50):\n","  start = time.time()\n","\n","  loss_sum = 0\n","  for x_batch,y_batch in dataset:\n","    loss = train_step(x_batch,y_batch,t_v)\n","    loss_sum += loss\n","  print('time for epoch{}is {} sec: training_loss = {}'.format(epoch+1,time.time()-start,loss))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":860},"id":"MWcyP6dUpXCT","outputId":"1f4e11ed-d289-4ca1-ca08-d778bfdf2f51","executionInfo":{"status":"error","timestamp":1700723109408,"user_tz":-540,"elapsed":1500841,"user":{"displayName":"송우석","userId":"17544301414917834266"}}},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["time for epoch1is 92.94394588470459 sec: training_loss = 4.2454447746276855\n","time for epoch2is 64.71694159507751 sec: training_loss = 4.058753967285156\n","time for epoch3is 60.93182349205017 sec: training_loss = 3.6805193424224854\n","time for epoch4is 63.69733119010925 sec: training_loss = 3.3260550498962402\n","time for epoch5is 81.90356755256653 sec: training_loss = 2.8478100299835205\n","time for epoch6is 60.30056381225586 sec: training_loss = 3.32228946685791\n","time for epoch7is 81.90387010574341 sec: training_loss = 2.4085617065429688\n","time for epoch8is 61.744802474975586 sec: training_loss = 2.4996538162231445\n","time for epoch9is 81.90269041061401 sec: training_loss = 2.277601957321167\n","time for epoch10is 60.33395767211914 sec: training_loss = 1.9484912157058716\n","time for epoch11is 81.90353059768677 sec: training_loss = 1.8914361000061035\n","time for epoch12is 59.349772930145264 sec: training_loss = 1.9507839679718018\n","time for epoch13is 81.90364956855774 sec: training_loss = 1.6822960376739502\n","time for epoch14is 61.235180616378784 sec: training_loss = 1.6827648878097534\n","time for epoch15is 81.90361547470093 sec: training_loss = 1.772209644317627\n","time for epoch16is 59.23966693878174 sec: training_loss = 1.5630697011947632\n","time for epoch17is 81.90388917922974 sec: training_loss = 1.5437910556793213\n","time for epoch18is 59.477354764938354 sec: training_loss = 1.0645641088485718\n","time for epoch19is 81.90377569198608 sec: training_loss = 1.0620322227478027\n","time for epoch20is 59.62976408004761 sec: training_loss = 0.9367425441741943\n"]},{"output_type":"error","ename":"KeyboardInterrupt","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)","    \u001b[0;31m[... skipping hidden 1 frame]\u001b[0m\n","\u001b[0;32m<ipython-input-59-01d7b94fa97f>\u001b[0m in \u001b[0;36m<cell line: 3>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      7\u001b[0m   \u001b[0;32mfor\u001b[0m \u001b[0mx_batch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0my_batch\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mdataset\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m     \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_step\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_batch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0my_batch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mt_v\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m     \u001b[0mloss_sum\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m<ipython-input-39-955e837e5588>\u001b[0m in \u001b[0;36mtrain_step\u001b[0;34m(x, y, t_v)\u001b[0m\n\u001b[1;32m      7\u001b[0m   \u001b[0mgradients\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtape\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgradient\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mt_v\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m   \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply_gradients\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgradients\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mt_v\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m   \u001b[0;32mreturn\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/keras/src/optimizers/optimizer.py\u001b[0m in \u001b[0;36mapply_gradients\u001b[0;34m(self, grads_and_vars, name, skip_gradients_aggregation, **kwargs)\u001b[0m\n\u001b[1;32m   1222\u001b[0m             \u001b[0mgrads_and_vars\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maggregate_gradients\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgrads_and_vars\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1223\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply_gradients\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgrads_and_vars\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1224\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/keras/src/optimizers/optimizer.py\u001b[0m in \u001b[0;36mapply_gradients\u001b[0;34m(self, grads_and_vars, name)\u001b[0m\n\u001b[1;32m    651\u001b[0m             \u001b[0mgrads_and_vars\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgrads\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrainable_variables\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 652\u001b[0;31m             \u001b[0miteration\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_internal_apply_gradients\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgrads_and_vars\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    653\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/keras/src/optimizers/optimizer.py\u001b[0m in \u001b[0;36m_internal_apply_gradients\u001b[0;34m(self, grads_and_vars)\u001b[0m\n\u001b[1;32m   1252\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1253\u001b[0;31m         return tf.__internal__.distribute.interim.maybe_merge_call(\n\u001b[0m\u001b[1;32m   1254\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_distributed_apply_gradients_fn\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/distribute/merge_call_interim.py\u001b[0m in \u001b[0;36mmaybe_merge_call\u001b[0;34m(fn, strategy, *args, **kwargs)\u001b[0m\n\u001b[1;32m     50\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0mstrategy_supports_no_merge_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 51\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstrategy\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     52\u001b[0m   \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/keras/src/optimizers/optimizer.py\u001b[0m in \u001b[0;36m_distributed_apply_gradients_fn\u001b[0;34m(self, distribution, grads_and_vars, **kwargs)\u001b[0m\n\u001b[1;32m   1344\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mgrad\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvar\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mgrads_and_vars\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1345\u001b[0;31m             distribution.extended.update(\n\u001b[0m\u001b[1;32m   1346\u001b[0m                 \u001b[0mvar\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mapply_grad_to_update_var\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgrad\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgroup\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/distribute/distribute_lib.py\u001b[0m in \u001b[0;36mupdate\u001b[0;34m(self, var, fn, args, kwargs, group)\u001b[0m\n\u001b[1;32m   3010\u001b[0m       \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_container_strategy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mscope\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3011\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_update\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvar\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgroup\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3012\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/distribute/distribute_lib.py\u001b[0m in \u001b[0;36m_update\u001b[0;34m(self, var, fn, args, kwargs, group)\u001b[0m\n\u001b[1;32m   4080\u001b[0m     \u001b[0;31m# except _update() passes `var` as the first argument to `fn()`.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 4081\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_update_non_slot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvar\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mvar\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mtuple\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgroup\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   4082\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/distribute/distribute_lib.py\u001b[0m in \u001b[0;36m_update_non_slot\u001b[0;34m(self, colocate_with, fn, args, kwargs, should_group)\u001b[0m\n\u001b[1;32m   4086\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mUpdateContext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcolocate_with\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 4087\u001b[0;31m       \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   4088\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mshould_group\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/autograph/impl/api.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    595\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mag_ctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mControlStatusCtx\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstatus\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mag_ctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mStatus\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mUNSPECIFIED\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 596\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    597\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/keras/src/optimizers/optimizer.py\u001b[0m in \u001b[0;36mapply_grad_to_update_var\u001b[0;34m(var, grad)\u001b[0m\n\u001b[1;32m   1339\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjit_compile\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1340\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_update_step_xla\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgrad\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvar\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mid\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_var_key\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvar\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1341\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/util/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    149\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 150\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    151\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    830\u001b[0m       \u001b[0;32mwith\u001b[0m \u001b[0mOptionalXlaContext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jit_compile\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 831\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    832\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    875\u001b[0m       \u001b[0;31m# run the first trace but we should fail if variables are created.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 876\u001b[0;31m       results = tracing_compilation.call_function(\n\u001b[0m\u001b[1;32m    877\u001b[0m           \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_variable_creation_config\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/eager/polymorphic_function/tracing_compilation.py\u001b[0m in \u001b[0;36mcall_function\u001b[0;34m(args, kwargs, tracing_options)\u001b[0m\n\u001b[1;32m    131\u001b[0m   \u001b[0mkwargs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 132\u001b[0;31m   function = trace_function(\n\u001b[0m\u001b[1;32m    133\u001b[0m       \u001b[0margs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtracing_options\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtracing_options\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/eager/polymorphic_function/tracing_compilation.py\u001b[0m in \u001b[0;36mtrace_function\u001b[0;34m(args, kwargs, tracing_options)\u001b[0m\n\u001b[1;32m    177\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 178\u001b[0;31m     concrete_function = _maybe_define_function(\n\u001b[0m\u001b[1;32m    179\u001b[0m         \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtracing_options\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/eager/polymorphic_function/tracing_compilation.py\u001b[0m in \u001b[0;36m_maybe_define_function\u001b[0;34m(args, kwargs, tracing_options)\u001b[0m\n\u001b[1;32m    220\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 221\u001b[0;31m   current_func_context = function_context.make_function_context(\n\u001b[0m\u001b[1;32m    222\u001b[0m       \u001b[0mtracing_options\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mscope_type\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/eager/polymorphic_function/function_context.py\u001b[0m in \u001b[0;36mmake_function_context\u001b[0;34m(scope_type)\u001b[0m\n\u001b[1;32m     99\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 100\u001b[0;31m   return function_cache.FunctionContext(\n\u001b[0m\u001b[1;32m    101\u001b[0m       EagerContext(\n","\u001b[0;32m<string>\u001b[0m in \u001b[0;36m<lambda>\u001b[0;34m(_cls, context, scope_type)\u001b[0m\n","\u001b[0;31mKeyboardInterrupt\u001b[0m: ","\nDuring handling of the above exception, another exception occurred:\n","\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)","\u001b[0;31mKeyboardInterrupt\u001b[0m: "]}]},{"cell_type":"code","source":["!pip3 install pyyaml h5py"],"metadata":{"id":"VidgDXBzqISU"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":[],"metadata":{"id":"2hbnKHau1bV7"}},{"cell_type":"code","source":["def translate(src,max_steps = 100):\n","  src_tokens = np.array([x_vocab[x] for x in hannanum.morphs(src)])\n","  src_tokens = np.insert(src_tokens,0,[1])\n","  src_tokens = np.append(src_tokens,2)\n","  x_test = tf.expand_dims(src_tokens,axis =0)\n","  _,s1,s2,s3 = encoder(x_test,training = False)\n","\n","  y_test = tf.expand_dims(tf.constant([y_vocab['<bos>']]),axis = 0)\n","  output_seq = []\n","  for _ in range(max_steps):\n","    logits,s1,s2,s3 = decoder([y_test,s1,s2,s3],training = False)\n","    y_test = tf.argmax(logits,axis =2)\n","    #print(y_test)\n","    pred = tf.squeeze(y_test,axis =0)\n","    #print(pred)\n","\n","    if pred == y_vocab['<eos>']:\n","      #print(\"zz\")\n","      break\n","    output_seq.append(pred.numpy())\n","  return ' '.join([inverse_y_vocab[x[0]] for x in output_seq])"],"metadata":{"id":"3NEIMkrBq9uE"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["translate('잘 안 되네')"],"metadata":{"id":"iQ5NSi6_rB5-","colab":{"base_uri":"https://localhost:8080/","height":35},"executionInfo":{"status":"ok","timestamp":1700723120632,"user_tz":-540,"elapsed":461,"user":{"displayName":"송우석","userId":"17544301414917834266"}},"outputId":"ba479ab0-e963-4e4e-9e88-e50183da5bb3"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["\"do n't be so silly .\""],"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"}},"metadata":{},"execution_count":61}]},{"cell_type":"code","source":["def beam_translate(src,max_steps = 100,k = 16):\n","  src_tokens = np.array([x_vocab[x] for x in hannanum.morphs(src)])\n","  src_tokens = np.insert(src_tokens,0,[1])\n","  src_tokens = np.append(src_tokens,2)\n","  x_test = tf.expand_dims(src_tokens,axis =0)\n","  _,s1,s2,s3 = encoder(x_test,training = False)\n","\n","  last_token = tf.constant([y_vocab['<bos>']])\n","  candidates = [(0.,tf.expand_dims(last_token,axis = 0),s1,s2,s3,[int(last_token)],False)]\n","\n","  for _ in range(max_steps):\n","    new_candidates = []\n","    for score , token,s1,s2,s3,output_seq,eos in candidates :\n","      if eos:\n","        new_candidates.append((score,token,s1,s2,s3,output_seq,eos))\n","        continue\n","      logits,s1,s2,s3 = decoder([token,s1,s2,s3],training = False)\n","      probs = tf.nn.log_softmax(logits,axis =2)\n","      values, indices = tf.math.top_k(tf.squeeze(probs),k=k)\n","      for prob, idx in zip(values, indices):\n","        eos = (int(idx)==y_vocab['<eos>'])\n","        last_token = tf.constant([int(idx)])\n","        new_candidates.append(\n","            (score +float(prob),tf.expand_dims(last_token,axis= 0),s1,s2,s3,\n","             output_seq + [int(last_token)],eos)\n","        )\n","    candidates = sorted(new_candidates, key = lambda t: -t[0])[:k]\n","  return [(candidates[i][0],' '.join([inverse_y_vocab[x] for x in candidates[i][5]])) for i in range(k)]"],"metadata":{"id":"OEQeVJR2sTwI"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["beam_translate('잘 안되네')"],"metadata":{"id":"uERxjGxUvmcy","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1700723124752,"user_tz":-540,"elapsed":4130,"user":{"displayName":"송우석","userId":"17544301414917834266"}},"outputId":"2b944585-ce20-4749-e21e-b7861c480e02"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["[(-4.257024133454252, \"<bos> it 's not a liar . <eos>\"),\n"," (-4.706906879146118, \"<bos> do n't you like it ? <eos>\"),\n"," (-4.754112625028938, \"<bos> do n't you laugh ? <eos>\"),\n"," (-4.8033481109305285, \"<bos> you 're mine . <eos>\"),\n"," (-4.8747765948064625, \"<bos> do n't you ? <eos>\"),\n"," (-5.192608612705953, \"<bos> do n't you like me ? <eos>\"),\n"," (-5.2122524314327165, \"<bos> do n't you leave ? <eos>\"),\n"," (-5.272478144150227, \"<bos> do n't you do that ? <eos>\"),\n"," (-5.3478018215391785, \"<bos> you 're lonely . <eos>\"),\n"," (-5.731973258632934, \"<bos> it 's not a fault . <eos>\"),\n"," (-5.853176517717657, \"<bos> do n't you do that . <eos>\"),\n"," (-6.110417670832248, \"<bos> do n't you help me ? <eos>\"),\n"," (-6.424333076298353, \"<bos> do n't you do it ? <eos>\"),\n"," (-7.164485688488639, \"<bos> do n't you like a passport . <eos>\"),\n"," (-7.188707823494042, \"<bos> do n't you like a passport ? <eos>\"),\n"," (-7.2123451717197895, \"<bos> do n't you like a cell phone . <eos>\")]"]},"metadata":{},"execution_count":63}]},{"cell_type":"code","source":["위의 코드를 통해 autoencoder 모델을 훈련시켰다.\n","i want to show the output sequence with the test images(example_input_batch[0])\n","Use greedy search for prediction\n","\n","밑의 코드를 조금 수정해서 beam_translate function을 정의해줘.\n","\n","beam_translate(tf.expand_dims(example_input_batch[0], axis=0))를 실행하면 output sequence가 출력되도록 해줘 .\n","example_input_batch[0].shape is  TensorShape([28, 28, 1])"],"metadata":{"id":"UWMGSAV-vq9k"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["\n","밑의 코드들을 수정해서 image를 넣으면 output seq가 나오는 모델을 학습하는 코드 알려줘\n","형식만  밑의 코드를 따라가고 세부 설정은 밑의 설명에 따라서 수정해줘\n","\n","\n","input_imgs.shape is (4434, 28, 28, 1)\n","\n","output_seqs.shape is  (4434, 202)\n","Encoder is a CNN that outputs a 10-dim latent vector with\n","an input image and Decoder is 3 layers of LSTMs\n","\n","\n","def build_encoder():\n","  input_seq = tf.keras.layers.Input((None,))\n","  x= tf.keras.layers.Embedding(x_vocab_size, embedding_dim)(input_seq)\n","  x,s1 = tf.keras.layers.GRU(latent_dim,name = 'encoder_gru1',\n","                             return_sequences = True,\n","                             return_state = True,\n","                             recurrent_initializer='glorot_uniform')(x,mask=tf.cast(input_seq !=0,bool))\n","  x,s2 = tf.keras.layers.GRU(latent_dim,name = 'encoder_gru2',\n","                             return_sequences = True,\n","                             return_state = True,\n","                             recurrent_initializer='glorot_uniform')(x,mask=tf.cast(input_seq !=0,bool))\n","  x,s3 = tf.keras.layers.GRU(latent_dim,name = 'encoder_gru3',\n","                             return_sequences = True,\n","                             return_state = True,\n","                             recurrent_initializer='glorot_uniform')(x,mask=tf.cast(input_seq !=0,bool))\n","  model = tf.keras.Model(input_seq,[x,s1,s2,s3])\n","  return model\n","encoder = build_encoder()\n","\n","def build_decoder():\n","  target_seq = tf.keras.layers.Input((None,))\n","  s1 = tf.keras.layers.Input((latent_dim,))\n","  s2 = tf.keras.layers.Input((latent_dim,))\n","  s3 = tf.keras.layers.Input((latent_dim,))\n","\n","  embedding = tf.keras.layers.Embedding(y_vocab_size, embedding_dim)(target_seq)\n","  x,output_s1 = tf.keras.layers.GRU(latent_dim,name = 'decoder_gru1',\n","                             return_sequences = True,\n","                             return_state = True,\n","                             recurrent_initializer='glorot_uniform')(embedding,initial_state =s1,mask=tf.cast(target_seq !=0,bool))\n","\n","  x,output_s2 = tf.keras.layers.GRU(latent_dim,name = 'decoder_gru2',\n","                             return_sequences = True,\n","                             return_state = True,\n","                             recurrent_initializer='glorot_uniform')(x,initial_state =s2,mask=tf.cast(target_seq !=0,bool))\n","  x,output_s3 = tf.keras.layers.GRU(latent_dim,name = 'decoder_gru3',\n","                             return_sequences = True,\n","                             return_state = True,\n","                             recurrent_initializer='glorot_uniform')(x,initial_state =s3,mask=tf.cast(target_seq !=0,bool))\n","  logits = tf.keras.layers.Dense(y_vocab_size)(x)\n","  model = tf.keras.Model([target_seq,s1,s2,s3],[logits,output_s1,output_s2,output_s3])\n","  return model\n","\n","decoder = build_decoder()\n","loss_func = tf.keras.losses.SparseCategoricalCrossentropy(from_logits =True, reduction ='none')\n","def batch_loss(y_true, y_pred):\n","  loss = loss_func(y_true,y_pred)\n","  mask = tf.cast(y_true != 0, tf.float32)\n","  loss = loss *mask\n","  return tf.reduce_sum(loss)/tf.reduce_sum(mask)\n","\n","optimizer = tf.keras.optimizers.Adam(1e-4)\n","def predict(x,y,training=True):\n","  _,ls1,ls2,ls3 = encoder(x,training =training)\n","  logits, _,_,_ = decoder([y,ls1,ls2,ls3],training = training)\n","  return logits\n","\n","def train_step(x,y,t_v):\n","  x= x[:,:tf.reduce_max(tf.math.count_nonzero(x,axis=1))]\n","  y= y[:,:tf.reduce_max(tf.math.count_nonzero(y,axis=1))]\n","  with tf.GradientTape() as tape:\n","    logits  =predict(x,y)\n","    loss = batch_loss(y[:,1:],logits[:,:-1,:])\n","  gradients = tape.gradient(loss,t_v)\n","  optimizer.apply_gradients(zip(gradients, t_v))\n","  return loss\n","\n","t_v = encoder.trainable_variables +decoder.trainable_variables\n","\n","for epoch in range(50):\n","  start = time.time()\n","\n","  loss_sum = 0\n","  for x_batch,y_batch in dataset:\n","    loss = train_step(x_batch,y_batch,t_v)\n","    loss_sum += loss\n","  print('time for epoch{}is {} sec: training_loss = {}'.format(epoch+1,time.time()-start,loss))"],"metadata":{"id":"buo2-yT8_ncv"},"execution_count":null,"outputs":[]}]}